{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "import  torch.nn as nn\n",
    "from net.models.cvae import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "[Encoder(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dModule(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DownSample(\n",
      "      (features): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2dModule(\n",
      "          (features): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): DownSample(\n",
      "      (features): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2dModule(\n",
      "          (features): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): DownSample(\n",
      "      (features): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2dModule(\n",
      "          (features): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): DownSample(\n",
      "      (features): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2dModule(\n",
      "          (features): Sequential(\n",
      "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv2dModule(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Flatten()\n",
      "  )\n",
      "), GumbelSoftmax(\n",
      "  (features): Linear(in_features=1152, out_features=16, bias=True)\n",
      ")]\n",
      "72\n",
      "2\n",
      "24\n",
      "2\n",
      "2\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'x_shape': (1, 486, 486),\n",
    "    'y_dim': 16,\n",
    "    'z_dim': 512,\n",
    "    'bottle_channel': 32,\n",
    "    'poolings': (3, 3, 3, 3),\n",
    "    'kernels': (3, 3, 3, 3),\n",
    "    'channels': (64, 128, 256, 64),\n",
    "    'pool_func': 'max',\n",
    "    'act_func': 'ReLU'\n",
    "}\n",
    "model = CVAE(**kwargs)\n",
    "classifier = nn.Sequential(*list(model.children())[:2])\n",
    "\n",
    "print(next(model.parameters()).device)\n",
    "print([p for p in classifier.children()])\n",
    "print(len([p for p in model.parameters()]))\n",
    "print(len([p for p in model.classifier.parameters()]))\n",
    "print(len([p for p in model.encoder.parameters()]))\n",
    "print(len([p for p in model.z.parameters()]))\n",
    "print(len([p for p in model.z_prior.parameters()]))\n",
    "print(len([p for p in model.decoder.parameters()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8475)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(100)\n",
    "b = a.softmax(-1)\n",
    "-(a * torch.log(b)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9831, -1.9831, -1.7831, -1.3831, -1.7831, -1.9831])\n",
      "tensor([-1.9831, -1.9831, -1.7831, -1.3831, -1.7831, -1.9831])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "logits = torch.Tensor([0,0,.2,.6,.2,0])\n",
    "\n",
    "a = F.log_softmax(logits, dim=-1)\n",
    "b = torch.log(F.softmax(logits, dim=-1))\n",
    "print(a.log_softmax(-1).log_softmax(-1))\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5715, -5.1781, -2.8975, -0.0375, -2.0613, -0.1986, -4.1890, -2.9825,\n",
       "        -6.1498, -4.2709])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def log_norm(x, mean, var):\n",
    "    return -0.5 * (torch.log(2.0 * np.pi * var) * torch.pow(x - mean, 2) / var )\n",
    "x = torch.randn(10)\n",
    "mean = torch.randn(10)\n",
    "var = F.softplus(torch.randn(10)) + 1e-8\n",
    "log_norm(x, mean, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8462)\n"
     ]
    }
   ],
   "source": [
    "logits  = torch.Tensor([1,0,0,1,1,0])\n",
    "p = logits.softmax(-1)\n",
    "log_p = logits.log_softmax(-1)\n",
    "entropy = -(p * log_p).sum(-1)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
